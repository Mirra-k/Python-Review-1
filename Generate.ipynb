{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self, n=1):\n",
    "        \"\"\"\n",
    "        :n: n в n-грамме.\n",
    "        :data: массив словарей(индекс - n-грамма, \n",
    "            значение - словарь(ключ - слово, значение - количество его вхождений)\n",
    "        :__wnc: ключ в словаре для каждого индекса. \n",
    "            Его значение - Сумма количеств свсех слов для данного ключа.\n",
    "        \"\"\"\n",
    "        self.n = n + 1\n",
    "        self.data = {}\n",
    "        self.__wnc = '_total_word_num'\n",
    "        \n",
    "    def load(self, file_name):\n",
    "        \"\"\"\n",
    "        Загружает массив словарей из текста в data.\n",
    "        :file_name: имя файла, из которого мы берем информацию.\n",
    "        :return: nothing\n",
    "        \"\"\"\n",
    "        with open(file_name) as file1:\n",
    "            buffer = json.load(file1)\n",
    "        self.data = {}\n",
    "        for key in buffer.keys():\n",
    "            self.data[tuple(key.split(' '))] = buffer[key]\n",
    "        self.n = len(list(self.data.keys())[:1])\n",
    "      \n",
    "    def _preprocess(self):\n",
    "        \"\"\"\n",
    "        Для каждого значения для n-граммы считает вероятность вхождения слова.\n",
    "        (нормирует частоты)\n",
    "        :b: значение __wnc для каждой n-граммы.\n",
    "        :predata: массив, в котором хранятся слова и вероятность их вхождения для каждой n-граммы.\n",
    "        :return: nothing\n",
    "        \"\"\"\n",
    "        self.predata = {}\n",
    "        for ngr in self.data.keys():\n",
    "            self.predata[ngr] = []\n",
    "            self.predata[ngr].append(list(self.data[ngr].keys()))\n",
    "            b = self.data[ngr][self.__wnc]\n",
    "            self.data[ngr][self.__wnc] = 0\n",
    "            self.predata[ngr].append(np.array(list(self.data[ngr].values())))\n",
    "            self.predata[ngr][1] = self.predata[ngr][1] / np.int(b)\n",
    "        \n",
    "    \n",
    "    def _get_random_after(self, ngr):\n",
    "        \"\"\"\n",
    "        С помощью np.random.choice выдает случайное слово.\n",
    "        :ngr: n-грамма, для которой мы ищем следующее слово.\n",
    "        :return: слово для заданной n-граммы. \n",
    "        \"\"\"\n",
    "        return np.random.choice(self.predata[tuple(ngr)][0], p=self.predata[tuple(ngr)][1])\n",
    "            \n",
    "    def getText(self, word, text_len):\n",
    "        \"\"\"\n",
    "        По заданному слову генерирует последовательность заданной длины.\n",
    "        :word: начальное слово.\n",
    "        :text_len: длина последовательности.\n",
    "        :st: Необходимая последовательность\n",
    "        :cur_ngram: n-грамма, по которой ищем следующее слово.\n",
    "        :return: последовательность заданной длины. \n",
    "        \"\"\"\n",
    "        st = word\n",
    "        cur_ngram = [word]\n",
    "        self.preprocess()\n",
    "        for i in range(1, text_len):\n",
    "            word = self._get_random_after(cur_ngram)\n",
    "            st += \" \" + word\n",
    "            if len(cur_ngram) < self.n - 1:\n",
    "                cur_ngram.append(word)\n",
    "            else:\n",
    "                cur_ngram = cur_ngram[1:]\n",
    "                cur_ngram.append(word)\n",
    "            \n",
    "        return st\n",
    "\n",
    "n = 1\n",
    "m = Model(n)\n",
    "    \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model\", help=\"path to the file from which the model is loaded\")\n",
    "parser.add_argument(\"--seed\", help=\"The initial word\")\n",
    "parser.add_argument(\"--length\", type=int, help=\"length of the generated sequence\")\n",
    "parser.add_argument(\"--output\", help=\"The file to which the result will be written\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "m.load(args.output)\n",
    "\n",
    "if args.output:\n",
    "    open(file_name, 'w').write(json.dumps(getText(args.seed), args.length)) \n",
    "else:\n",
    "    print(getText(args.seed), args.length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
